{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  clases genéricas\n",
    "import numpy as np\n",
    "import os\n",
    "#import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout, Dense, Input, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.metrics import  confusion_matrix, roc_auc_score, f1_score,  precision_score, recall_score #, roc_curve, auc\n",
    "\n",
    "\n",
    "from keras.preprocessing import image as keras_image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# def load_image(df_image_path, inputShape):\n",
    "#     \"\"\"Load grayscale image\n",
    "#     :param image_path: path to image to load\n",
    "#     :return: loaded image\n",
    "#     \"\"\"\n",
    "    \n",
    "#     imagens = []\n",
    "#     for i in range(df_image_path.shape[0]):\n",
    "#         image_path = df_image_path[i]   \n",
    "#         img = Image.open(image_path)\n",
    "#         img = img.convert('RGB')\n",
    "#         img = img.resize(inputShape)\n",
    "#         img = np.asarray(img)\n",
    "    \n",
    "        \n",
    "#         #img = keras_image.load_img(image_path, target_size = inputShape, interpolation = 'bicubic', color_mode = \"rgb\")\n",
    "#         #img = 255.0*np.array(img) / (1.0*np.nanmax(img))\n",
    "#         imagens.append(img)\n",
    "#     return imagens   #  [0,255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karem/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### Definir paths em meu computador                 \n",
    "\n",
    "Path_open_csv = 'CSV_Files/'\n",
    "Path_images = 'Covid19_RadiograpyDataset/'\n",
    "Path_save_result = 'Result/'  ## definir pasta onde salvar pesos e log\n",
    "Path_Open_peso = 'Experiment/'  ## definir pasta onde salvar pesos e log\n",
    "\n",
    "term_imagem = '.png'\n",
    "\n",
    "### Definir parâmetros\n",
    "width       = 224 \n",
    "height      = 224\n",
    "depth       = 3                 # 3 se RGB, 1 se grayscale (weights_ini= None)\n",
    "inputShape  = [height, width, depth]\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#                   carregar e montar csv de test\n",
    "################################################################################################\n",
    "data_test = pd.DataFrame()\n",
    "data_test_temp = pd.read_csv(Path_open_csv + 'test.csv')\n",
    "data_test_temp['Image_name'] = data_test_temp['folder'] + data_test_temp['image_name'] + term_imagem\n",
    "data_test = data_test_temp[['Image_name', 'label']]\n",
    "\n",
    "\n",
    "#### montar vector covid=1 normal=0\n",
    "data_test['classVector'] =  data_test['label']\n",
    "data_test['Path'] =  Path_images + data_test['Image_name'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_images = load_image(data_test['Path'], inputShape[0:2])\n",
    "# label_test = data_test['classVector']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de salvamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_folders(path):\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_object(obj, filename):\n",
    "#     with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "#         pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede = 'VGG19'\n",
    "#'NASNetLarge' #'DenseNet201', 'MobileNetV2', 'ResNet50V2', 'VGG19', 'VGG16', 'EfficientNetB0', 'EfficientNetB4'\n",
    "#'Xception', 'InceptionV3', 'InceptionResNetV2'\n",
    "weights_ini = 'imagenet'  # 'imagenet'  None\n",
    "NUM_EPOCHS = 80\n",
    "BATCH_SIZE  = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#                                Dados do treino \n",
    "################################################################################################\n",
    "\n",
    "l_nome_proceso = 'CNN_mlp'\n",
    "experimento = l_nome_proceso + '_WH_' + str(width) \n",
    "\n",
    "### definir pasta onde esta o peso treinado\n",
    "Path_Open_peso_bes   = Path_Open_peso + '/Models/' + experimento +  '/'\n",
    "\n",
    "### Criar pastas onde estão os pesos\n",
    "#create_folders(Path_Open_peso)\n",
    "\n",
    "### definir nomes de arquivos de saida\n",
    "palavra_s = 'ensaio_' + rede + '_' + weights_ini + '_WH_' + str(width)       \n",
    "arquivo_best_peso = os.path.sep.join([Path_Open_peso_bes, palavra_s + \".hdf5\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_GeneratorRx(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data_path_img, data_lab, index_b, batch_size=BATCH_SIZE, inputShape=inputShape, aug = 0, shuffle=True):            \n",
    "        'Initialization'\n",
    "        if aug == 1:\n",
    "            data_gen = ImageDataGenerator(  \n",
    "                                        rotation_range     = 15,\n",
    "                                        # zoom_range         = 0.05,\n",
    "                                        width_shift_range  = 0.1,\n",
    "                                        height_shift_range = 0.1,\n",
    "                                        # shear_range        = 0.01,\n",
    "                                        horizontal_flip    = True,\n",
    "                                        fill_mode          = \"nearest\",\n",
    "                                        preprocessing_function = preprocess_input,\n",
    "                                        )\n",
    "        else:\n",
    "            data_gen = ImageDataGenerator(\n",
    "                                    preprocessing_function = preprocess_input, # se usar isto a imagem entrada deve ficar 0-255\n",
    "                                 )            \n",
    "        self.data_path_img  =  data_path_img   \n",
    "        self.labels         =  data_lab   \n",
    "        self.index_b        =  index_b    \n",
    "        self.batch_size     =  batch_size # int\n",
    "        self.inputShape     =  inputShape               # tuple int)\n",
    "        self.data_gen       =  data_gen\n",
    "        self.shuffle        =  shuffle\n",
    "        self.aug            =  aug\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "####################################################################################################################################\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "        :return: number of batches per epoch        \"\"\"\n",
    "        return int(np.ceil( len(self.data_path_img)  /  float(self.batch_size) ))\n",
    "    \n",
    "####################################################################################################################################\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "        ## Generate indexes of the batch\n",
    "        indexes = self.index_b[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        ## Find list of IDs (paths)\n",
    "        list_IDs_temp = [self.data_path_img[k] for k in indexes]\n",
    "        ## Generate data\n",
    "        X = self._generate_X(list_IDs_temp)\n",
    "        y = self.labels[indexes]                \n",
    "        ## Generate Augmented data\n",
    "        iterat = self.data_gen.flow(X, y, shuffle=self.shuffle)\n",
    "        X0,y0  = iterat.next()\n",
    "        y_mat  = np.array(np.uint32 (y0.tolist()) )\n",
    "        return X0,y_mat\n",
    "    \n",
    "####################################################################################################################################\n",
    "    def _generate_X(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size images\n",
    "        :param list_IDs_temp: list of image paths to load\n",
    "        :return: batch of images\n",
    "        \"\"\"\n",
    "        # Initialization\n",
    "        X = np.empty( (len(list_IDs_temp), *self.inputShape) )\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            X[i,] = self._load_image(ID)\n",
    "        return X\n",
    "    \n",
    "####################################################################################################################################\n",
    "    def _load_image(self, image_path):\n",
    "        \"\"\"Load grayscale image\n",
    "        :param image_path: path to image to load\n",
    "        :return: loaded image\n",
    "        \"\"\"\n",
    "        img = keras_image.load_img(image_path ,target_size=self.inputShape,interpolation='bicubic',color_mode = \"rgb\")\n",
    "        img = 255.0*np.array(img) / (1.0*np.nanmax(img))\n",
    "        return img   #  [0,255]\n",
    "    \n",
    "####################################################################################################################################\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.index_b = np.arange(len(self.data_path_img))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index_b)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, model_weights_ini, inputShape):        \n",
    "    if model_name   == 'ResNet50V2':                 \n",
    "        base_model = ResNet50V2(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))\n",
    "    \n",
    "    elif model_name == 'VGG16':          \n",
    "        base_model = VGG16(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))\n",
    "    \n",
    "    elif model_name == 'VGG19':            \n",
    "        base_model = VGG19(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))\n",
    "        \n",
    "    elif model_name == 'EfficientNetB4':        \n",
    "        base_model = EfficientNetB4(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))   \n",
    "        \n",
    "    elif model_name == 'EfficientNetB0':  \n",
    "        base_model = EfficientNetB0(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))\n",
    "        \n",
    "    elif model_name == 'MobileNetV2':             \n",
    "        base_model = MobileNetV2(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape)) \n",
    "    \n",
    "    elif model_name == 'DenseNet201':             \n",
    "        base_model = DenseNet201(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))   \n",
    "    \n",
    "    elif model_name == 'NASNetLarge':             \n",
    "        base_model = NASNetLarge(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape)) \n",
    "        \n",
    "    elif model_name == 'Xception':             \n",
    "        base_model = Xception(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))   \n",
    "        \n",
    "    elif model_name == 'InceptionV3':             \n",
    "        base_model = InceptionV3(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))   \n",
    "        \n",
    "    elif model_name == 'InceptionResNetV2':             \n",
    "        base_model = InceptionResNetV2(include_top=False,  weights = model_weights_ini, input_tensor=Input(shape=inputShape))   \n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rede == 'ResNet50V2': \n",
    "    from tensorflow.keras.applications import ResNet50V2\n",
    "    from tensorflow.keras.applications.resnet import preprocess_input\n",
    "elif rede == 'VGG16': \n",
    "    from tensorflow.keras.applications import VGG16\n",
    "    from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "elif rede == 'VGG19': \n",
    "    from tensorflow.keras.applications import VGG19\n",
    "    from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "elif rede == 'EfficientNetB4': \n",
    "    from keras_efficientnets import  EfficientNetB4\n",
    "    from keras_efficientnets import  preprocess_input  \n",
    "elif rede == 'EfficientNetB0':\n",
    "    from keras_efficientnets import  EfficientNetB0\n",
    "    from keras_efficientnets import  preprocess_input  \n",
    "elif rede == 'MobileNetV2': \n",
    "    from tensorflow.keras.applications import MobileNetV2\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "elif rede == 'DenseNet201': \n",
    "    from tensorflow.keras.applications import DenseNet201\n",
    "    from tensorflow.keras.applications.densenet import preprocess_input\n",
    "elif rede == 'NASNetLarge': \n",
    "    from tensorflow.keras.applications import NASNetLarge\n",
    "    from tensorflow.keras.applications.nasnet import preprocess_input    \n",
    "elif rede == 'Xception': \n",
    "    from tensorflow.keras.applications import Xception\n",
    "    from tensorflow.keras.applications.xception import preprocess_input    \n",
    "elif rede == 'InceptionV3': \n",
    "    from tensorflow.keras.applications import InceptionV3\n",
    "    from tensorflow.keras.applications.inception_v3 import preprocess_input    \n",
    "elif rede == 'InceptionResNetV2': \n",
    "    from tensorflow.keras.applications import InceptionResNetV2\n",
    "    from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### definir dictionario para apontador dentro do generator\n",
    "paramsB = {\n",
    "              'batch_size': BATCH_SIZE,\n",
    "              'inputShape': inputShape,\n",
    "          } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#                  Montar CONV net\n",
    "################################################################################################\n",
    "##  carregar modelo base\n",
    "base_model = get_model(rede, weights_ini, inputShape)\n",
    "## construir MLP\n",
    "headModel = base_model.output\n",
    "headModel = GlobalAveragePooling2D()(headModel)\n",
    "headModel = BatchNormalization()(headModel)\n",
    "headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.3)(headModel)                      # orig = 0.5\n",
    "headModel = Dense(1, activation=\"sigmoid\", name=\"pred\")(headModel)\n",
    "\n",
    "## place the head FC model on top of the base model (this will become the actual model we will train)\n",
    "model = Model(inputs=base_model.input, outputs=headModel, name=\"Classifica\")\n",
    "\n",
    "## carregar pesos\n",
    "model.load_weights(arquivo_best_peso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#                  Montar generator\n",
    "################################################################################################  \n",
    "test_generator = Data_GeneratorRx(data_path_img = data_test['Path']  , data_lab = data_test['classVector'], index_b = np.arange(len(data_test)), **paramsB, aug = 0, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Classifica/block1_conv1/Conv2D (defined at <ipython-input-15-eaa1284fee81>:4) ]] [Op:__inference_predict_function_875]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-eaa1284fee81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#                  predecir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint32\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classVector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classVector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    648\u001b[0m               *args, **kwds)\n\u001b[1;32m    649\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Classifica/block1_conv1/Conv2D (defined at <ipython-input-15-eaa1284fee81>:4) ]] [Op:__inference_predict_function_875]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "################################################################################################\n",
    "#                  predecir\n",
    "################################################################################################\n",
    "y_pred = model.predict(test_generator,    verbose=1  )\n",
    "y_true = np.array(np.uint32 (data_test['classVector'].tolist()) ).reshape(len(data_test['classVector']),1)\n",
    "      \n",
    "## Assumir  threshold\n",
    "threshold = [0.5]\n",
    "AUC     = roc_auc_score(y_true, y_pred)  \n",
    "\n",
    "## Find prediction  applying threshold\n",
    "y_pred_bin = np.array([1 if prob >= threshold else 0 for prob in y_pred])\n",
    "y_pred_bin = y_pred_bin.reshape([len(y_pred_bin),1])\n",
    "\n",
    "## Calcular metricas\n",
    "tn0, fp0, fn0, tp0 = confusion_matrix(y_true , y_pred_bin).ravel()\n",
    "f1    = f1_score(y_true, y_pred_bin, average='binary')\n",
    "acc   = (tp0 + tn0) / (tp0 + tn0 + fp0+ fn0)\n",
    "ps    = precision_score(y_true , y_pred_bin)\n",
    "rec   = recall_score(y_true , y_pred_bin)\n",
    "\n",
    "## salvar metricas\n",
    "metricas = np.zeros([y_pred.shape[1],12])\n",
    "metricas[:] = [0,0, threshold[0],tp0, fp0, tn0, fn0, AUC, f1 , acc, ps, rec]\n",
    "salida   = pd.DataFrame(metricas).rename(columns={0:'rede', 1:'Base',  2:'threshold',3:'TP', 4:'FP', 5:'TN', 6:'FN', 7:'AUROC', 8:'F1', 9:'acc', 10:'prec', 11: 'rec'})\n",
    "salida['Base'] = 'exemplo cnn'\n",
    "salida['rede'] = rede\n",
    "\n",
    "salida.to_csv(Path_save_result + 'res_' + rede + '_' + weights_ini + '_WH_' + str(width) + '.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}